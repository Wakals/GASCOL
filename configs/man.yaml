### Example
## Input
# input rgba image path (default to None, can be load in GUI too)
input: 
seg_prompt: coat

scene: 'A man in black coat, yellow shirt, pink trousers, blue leather shoes and green hat is waving'
edit_prompt: ['black coat']
prompt: ['A man in black coat, yellow shirt, pink trousers, blue leather shoes and green hat is waving']
# prompt: ['Black coat']

floor:

center: [[0.0, 0.1, 0.0]]

edge: [[0.4, 0.8, 0.4]]

ori: [0]

# layout scale
layout_scale: 1
# input mesh for stage 2 (auto-search from stage 1 output path if None)
mesh:
# estimated elevation angle for input image 
elevation: -20
# reference image resolution
ref_size: 256
# density thresh for mesh extraction
density_thresh: 1
# floor point scale
floor_scale: 0.02

load_object: 

### Output
# outdir: bedroom
# save_path: bedroom

outdir: man
save_path: man

### Training
# enable overlap reg loss
overlap: False
# enable layout loss
layout: True
# enable scale loss
regloss: True
# guidance loss weights (0 to disable)
lambda_sd: 1
mvdream: True
lambda_zero123: 0
# training iterations
# iters: 20000
iters: 12000
# iters: 2000
# training camera radius
radius: 3
# training camera fovy
fovy: 49.1
# checkpoint to load (should be a ply file)
load:
# prob to invert background color during training (1 = always black, 0 = always white)
invert_bg_prob: 0.5
# interval for ControlNet
interval: 6

### GUI
gui: False
force_cuda_rast: False
# GUI resolution
H: 800
W: 800

### Gaussian splatting
# num_pts: 500000
num_pts: 120000
sh_degree: 0
position_lr_init: 0.00016
position_lr_final: 0.0000016
position_lr_delay_mult: 0.01
# position_lr_max_steps: 30000
position_lr_max_steps: 30000
feature_lr: 0.005
opacity_lr: 0.05
scaling_lr: 0.005
rotation_lr: 0.001

### Textured Mesh
geom_lr: 0.0001
texture_lr: 0.2